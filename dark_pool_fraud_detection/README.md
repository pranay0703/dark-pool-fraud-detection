
## Quick Start

### 1. Installation

```bash
# Clone the repository
git clone <repository-url>
cd dark_pool_fraud_detection

# Run setup script (recommended)
python setup.py

# Or install manually
pip install -r requirements.txt
```

### 2. Generate Sample Data

```bash
# The setup script will generate sample data automatically
# Or run manually:
python -c "from src.data_pipeline.data_loader import DarkPoolDataLoader; loader = DarkPoolDataLoader('configs/config.yaml'); loader.create_dataloaders()"
```

### 3. Train the Model

```bash
# Train with default configuration
python train.py

# Train with custom configuration
python train.py --config configs/config.yaml --seed 42
```

### 4. Evaluate the Model

```bash
# Evaluate the trained model
python evaluate.py --model models/best_model.pth --plot

# Evaluate with custom test data
python evaluate.py --model models/best_model.pth --test_data data/custom_test.parquet
```

### 5. Run Demo

```bash
# Run all demos
python demo.py --model models/best_model.pth

# Run specific demo
python demo.py --model models/best_model.pth --demo_type realtime --num_samples 100
```

## Model Architecture

### Integrated Model Components

1. **Temporal Graph Neural Network (TGNN)**
   - Memory modules for state tracking
   - Multi-head attention mechanisms
   - Dynamic relationship modeling

2. **Transformer Networks**
   - Sequential data processing
   - Self-attention mechanisms
   - Positional encoding

3. **HAR-BACD-V Hybrid Model**
   - Heterogeneous Autoregressive (HAR) components
   - Behavioral Autoregressive Conditional Duration (BACD)
   - Dual-stage attention mechanism

4. **Uncertainty Quantification**
   - Bayesian Neural Networks
   - Spectral-normalized Neural Gaussian Processes
   - Confidence calibration

5. **Explainability**
   - SHAP (SHapley Additive exPlanations)
   - LIME (Local Interpretable Model-agnostic Explanations)
   - Attention visualization

## Configuration

The system is configured via `configs/config.yaml`. Key configuration sections:

- **Data Configuration**: Data paths, batch sizes, sequence lengths
- **Model Configuration**: Architecture parameters for each component
- **Training Configuration**: Learning rates, optimizers, loss weights
- **Hardware Configuration**: Device settings, number of workers
- **Logging Configuration**: Log levels, output directories

## Performance Metrics

The system targets the following performance metrics:

- **Accuracy**: >95%
- **Latency**: <2.3ms per prediction
- **False Positive Rate**: <2%
- **F1 Score**: >0.90
- **AUC-ROC**: >0.95

## Testing

```bash
# Run all tests
python -m pytest tests/

# Run specific test
python -m pytest tests/test_models.py

# Run with coverage
python -m pytest --cov=src tests/
```

## Usage Examples

### Real-time Inference

```python
from src.inference.real_time_inference import RealTimeInference

# Initialize inference system
inference = RealTimeInference(
    model_path='models/best_model.pth',
    config_path='configs/config.yaml',
    max_latency_ms=2.3
)

# Make prediction
prediction = inference.predict_single(features)
print(f"Fraud probability: {prediction.fraud_probability}")
print(f"Confidence: {prediction.confidence}")
```

### Batch Processing

```python
from src.inference.real_time_inference import BatchInference

# Initialize batch inference
batch_inference = BatchInference(
    model_path='models/best_model.pth',
    config_path='configs/config.yaml'
)

# Process batch
predictions = batch_inference.predict_batch(features)
```

### Model Explanation

```python
from src.models.explainability import ModelExplainer

# Initialize explainer
explainer = ModelExplainer(model, feature_names, class_names)

# Generate explanations
explanations = explainer.explain_shap(features)
```

## Research Background

This project is based on cutting-edge research in:

- **Temporal Graph Neural Networks** for financial fraud detection
- **Transformer architectures** for sequential data analysis
- **Information asymmetry** detection in dark pools
- **Explainable AI** for regulatory compliance
- **Uncertainty quantification** in deep learning

## License

MIT License - see LICENSE file for details.

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## Support

For questions and support, please open an issue on GitHub.

## Acknowledgments

This project builds upon research from:
- Temporal Graph Neural Networks for fraud detection
- Transformer architectures for financial data
- Information asymmetry in dark pools
- Explainable AI methodologies
